---
layout: project
title: MAE 4300 Final Essay
description: Just a spaceship that I designed
technologies: [SolidWorks, Machining]
image: /assets/images/Alaska_737_Max_9.jpg
---

# Accountability and Ethical Decision-Making in the Boeing 737 MAX Case

## Introduction
The Boeing 737 MAX crashes are often described as a technical failure, but the ethical failure was broader and harder to pinpoint. Decisions about design, documentation, training, certification, and organizational incentives combined put the public at risk. The central question is not only what failed, but who had decision and authority, what duties they owed, and how they should have acted when safety concerns surfaced, and ultimately what lead to the crash.

Central Thesis: The 737 MAX case shows that accountability in engineering must be active, not passive, and how ASME Canon 1 (safety of the public) must override scheduling, cost pressure, and employer loyalty when life is on the line, and transparent communication are part of “safety,” not optional extras.

## Relevant Facts
To understand why this became an ethics issue (not just a “bad design” issue), you have to look at the facts on multiple levels: the system itself, the people making decisions, and the culture they were working inside.

On the technical side, MCAS design contributed directly to the Lion Air and Ethiopian crashes. The lack of redundancy (single AoA sensor dependence) created a single-point-of-failure vulnerability. Optional/disabled alerting meant pilots could be unaware of error in sensor conditions. Pilot training and notification about MCAS were omitted/minimized, while documentation of the technology was scarse. Certification shortcuts helped the aircraft reach market faster.

On the individual side (people’s decisions/actions), engineer concerns were raised early (single-sensor risk, lack of redundancy) but ignored/minimized. Test pilot warnings existed and should have triggered deeper review, but was quickly swept under the rug. FAA delegation and limited oversight shaped how risk was assessed. Maintenance/sensor issues (like faulty input) fed into MCAS’s vulnerability.

On the organizational side (policies/culture/incentives), corporate pressure favored speed-to-market over conservative safety margins. Delegated authority culture blurred boundaries between regulator and manufacturer. Profit-driven training policy (no extra training) incentives shaped decisions, which led to pilots being unaware of the intricacies of the technology. Internal communication breakdown reflected a culture that discouraged engineerings from speaking up against the safety risks. Boeing's post-crash response deepened mistrust and led to worldwide grounding of MCAS.

## Definitional Clarification
Before we can judge what Boeing, engineers, or the FAA *should* have done, we have to clarify what key ethical terms mean in this case. The 737 MAX controversy isn’t only about facts, it’s also about which definition of “safety” and “accountability” is being used. Boeing can appear “in the right” if safety is defined as "meeting minimum regulatory requirements," but the same actions look unethical if safety is defined as "preventing foreseeable catastrophic risk". I’m using this section to make those definitions explicit so that, in the next sections, I can justify which definition should control.

Safety (as defined by the entity) looks like this: Boeing sees it as regulatory compliance, victims’ families see it as prevention of foreseeable catastrophic risk, and the FAA sees it as federal airworthiness standards. So what? If safety = compliance, Boeing looks defensible. If safety equals risk prevention, minimizing redundancy/training looks negligent.

Accountability (as defined by the entity) also changes what “counts” as doing the right thing. Boeing can frame accountability as cooperation with investigations. Victims’ families frame it as public acknowledgement of wrongdoing. The FAA frames it as ensuring manufacturer + agency uphold oversight.

Integrity and responsibility also split depending on who you ask. Integrity can be “image” vs integrity as “truthfulness even when profits hurt.” Responsibility can be “following procedure” vs responsibility as “preventing foreseeable harm.” Morality can be “legal compliance” vs “human-centered protection of life.” These definitional differences explain why Boeing could argue “we complied,” while the public sees it as an ethical failure on Boeing's part.

## Ethical Analysis of Five Core Issues
Once the facts and definitions are clear, the ethical issues in this case can be broken into five main questions.

First, cost/schedule vs testing and validation. Should Boeing have rushed testing/validation due to cost/timeline pressure to compete? The stakeholders are basically everyone involved (passengers, pilots, airlines, Boeing engineers/management, regulators). The relevant canons are Canon 1 (public safety), Canon 2 (competence), and Canon 4 (faithful agent). The conflict is business pressure and deadlines vs conservative validation standards. The hierarchy decision is that Canon 1 overrides Canon 4 in life-critical systems. The resolution is that rushing validation to meet market pressure is ethically wrong because it increases foreseeable risk, to minimize timeline.

Second, documentation and transparency about MCAS. Should Boeing engineers have approved MCAS while providing incomplete/misleading documentation to regulators and/or leaving details out of public-facing materials? Stakeholders are FAA regulators, pilots, passengers, airlines, and Boeing. The relevant canons are Canon 1, Canon 2, and Canon 7 (truthful communication). The conflict is confidentiality/“company secrets” and schedule vs truthful disclosure needed for safety. Canon 7 supports Canon 1 because misleading docs create safety risk. So the resolution is that withholding safety-critical system behavior violates Canon 7 and contributes to violating Canon 1.

Third, pilot training vs cost/schedule. Should Boeing have prioritized pilot training over schedule/cost for MCAS? The stakeholders are pilots/passengers (primary), airlines/regulators (secondary), Boeing (decision-maker). The relevant canons are Canon 1 and Canon 2. The conflict is the “no new training” business incentive vs operational preparedness. The hierarchy is Canon 1 overrides corporate competitiveness. So the resolution is that minimizing training to accelerate production/reduce cost is ethically unacceptable in a life-critical system.

Fourth, regulatory oversight and accepting Boeing internal testing. Should FAA regulators have accepted Boeing internal testing/data without independent testing? Stakeholders are passengers, pilots, airline operators, FAA employees, Boeing management. Relevant canons are Canon 1, Canon 2, Canon 7. The conflict is limited FAA expertise/resources and timeline pressure vs independent verification duty. Canon 1 demands independent verification or third-party validation when stakes are catastrophic. So reliance on manufacturer testing alone is ethically wrong when it reduces meaningful oversight.

Fifth, internal objections and whistleblowing. Should Boeing engineers have raised internal objections or whistleblown when safety concerns about MCAS were ignored? Stakeholders are passengers (primary), families of victims/FAA (secondary), engineers (at risk). The relevant canons are Canon 1 vs Canon 4, and Canon 7. The conflict is job security and organizational retaliation vs duty to protect the public. Canon 1 is paramount and employer loyalty cannot outrank public safety. The resolution is engineers had an ethical duty to escalate concerns, failure to do so contributed to harm.

## Practical Constraints: Why the Ideal Ethical Action Didn’t Happen
A realistic ethics analysis must acknowledge constraints without excusing outcomes. Engineers risk firing, reputation loss, and financial instability if they challenge leadership. Engineers working in silos may not see the whole project or the full system-level risk. Whistleblowing channels can exist but reports can be discouraged or not make it anywhere meaningful. Business/timeline pressure matters too, shareholder and competition pressure to ship ASAP can make training or redesign feel like “months” of delay. Pilots and airlines may resist extra training requirements. FAA may lack in-house capacity to retest and may trust a company’s reputation in good faith. And hierarchy matters, higher ups can lock in design decisions (like single-sensor dependence), which limits what ground-level engineers can change.

These constraints explain how the failure persisted, but they do not overturn Canon 1’s ethical priority.

## Preventing Repeat Failures: Individual, Organizational, Systemic
At the individual level, stronger ethics training should be focused on recognizing Canon 1 > Canon 4 conflicts. Engineers should also be trained on documentation discipline (especially for systems that protect lives), and be encouraged to treat “don’t cut corners” as a priority, not a suggestion.

At the organizational level, Boeing needs a culture that encourages dissent and freedom to speak without retaliation. Boeing also needs transparent regulator communication norms and not hiding safety-critical details as “company secrets.” A real internal safety board with authority to slow/stop certification when risk is credible would help too.

At the systemic level, regulators should require independent validation of safety-critical systems (or third-party testing) instead of unilateral trust. The FAA should thoroughly vet documentation for new systems and require meaningful verification. Industry-wide standards should exist so new flight systems trigger standardized pilot training requirements.

## Conclusion
The 737 MAX case illustrates how ethical failure can come from a chain of “reasonable” business and procedural decisions that, together, violate the profession’s most basic duty. Like as my middle school gym teacher would say "if you keep cutting corners, you will end up a mile behind," a sequence of cutting corners and undermining ethical responsibility led to the catastrophy. Under ASME ethics, the hierarchy is clear: public safety is paramount, and transparency, training, and independent verification are not optional, they are part of what safety means. Accountability requires designing for foreseeable failure, communicating truthfully, empowering dissent, and ensuring oversight is real rather than symbolic.

## References
- U.S. House Committee on Transportation & Infrastructure, *Final Committee Report on the Boeing 737 MAX* (Sept. 2020).
- BBC, “Boeing Chief Fired but 737 Concern Persists” (Dec. 2019).
- The Guardian, “Designed by Clowns” (Jan. 2020).
- PBS Frontline, “Boeing’s Fatal Flaw” (Sept. 2021).
- Federal Aviation Administration, “Summary of the FAA’s Review of Boeing 737 MAX” (Aug. 2020).